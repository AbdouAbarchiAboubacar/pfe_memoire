
\chapter{Contribution and Results}
\minitoc
\thispagestyle{empty}
\newpage

\section{Introduction}
Nous présentons dans ce chapitre les notions vues dans les chapitres précédents appliquer à un dataset. Partant de la collecte et la préparation du dataset, de l’application de la théorie des réponses aux items pour un ajustement bayésiens des réponses obtenues par les apprenants, jusqu’aux clustering hard et soft des items basés sur la similarité.

\section{Approche proposée}


\section{Implémentations et résultats expérimentaux}

\subsection{Outils de développement}
les outils matériels et logiciels utilisés pour le développement sont :

\subsubsection{Materiels}

\begin{table}[H]
  \centering
  \begin{tabular}{cccc}
    \toprule
     \textbf{Marque} & \textbf{CPU} & \textbf{RAM} & \textbf{OS} \\
     \midrule
       \textbf{Lenovo Y40-80} & AMD Intel Core i5 2.20 GHz & 16Go & Windows10 64bits \\ \hline
       \multicolumn{4}{m{14cm}}{\centering Et Linux Ubuntu 20.04 LTS installé sur WSL2 }\\
    \bottomrule
  \end{tabular}
  \caption{Caractéristiques du matériels utilisés}
  \label{tabmat}
\end{table}

\textbf{WSL2 :} Windows Subsystem for Linux (WSL) est une couche de compatibilité permettant d'exécuter des exécutables binaires Linux de manière native sur Windows 10 et Windows Server 2019. WSL2 est une version améliorer de WSL1 qui introduit d'importants changements, notamment la présence d'un véritable noyau Linux \cite{craigloewen_msft} via un sous-ensemble de fonctionnalités Hyper-V. 

\subsubsection{Outils et packages}

\begin{table}[H]
	\centering
	\addtolength{\leftskip} {-4cm}
	\addtolength{\rightskip}{-4.5cm}
	\begin{tabular}{|m{5cm}|m{14cm}|}
	\hline
	\rowcolor{blueforest}
	\color{white} \textbf{Outils | Packages} & \color{white} \textbf{Description}  \\
	\hline\hline
	\multicolumn{2}{|m{19cm}|}{\centering Les outils et packages utilisés sur windows 10 : }\\ \hline
	\begin{center}
	    \begin{minipage}{.3\textwidth}
      \includegraphics[width=\textwidth]{images/chapitre7/python.png}
    \end{minipage}
	\end{center}
	\centering \textbf{Python} \cite{10.5555/1593511} & Créé par le développeur Guido Van Rossum et publié pour la première fois en 1991. Il permet aux programmeurs d'utiliser différents styles de programmation pour créer des programmes simples ou complexes. Python est l'un des langages de programmation les plus populaires pour la science des données. C'est un langage de programmation de haut niveau, structuré, open source, interprété et dynamique. Il est multiparadigme, multi-plateforme et multi-usages. La syntaxe de Python aide les programmeurs à coder en moins d'étapes par rapport à d'autres langages comme JAVA ou C++, ce qui facilite le travail et le rend plus rapide, facile et amusant à faire. Il possède une bibliothèque standard complète et volumineuse dotée d'une gestion automatique de la mémoire et de fonctionnalités dynamiques \cite{python_cours}. Dans notre travail, nous avons utilisé Python 3.5 intégré à Anaconda. \\ \hline
  \begin{center}
	    \begin{minipage}{.3\textwidth}
      \includegraphics[width=\textwidth]{images/chapitre7/anaconda.png}
    \end{minipage}
	\end{center}
	\centering \textbf{Anaconda} & Anaconda \cite{anaconda_citation} est une distribution libre et open source \cite{anaconda_website} des langages de programmation Python et R appliqué au développement d'applications dédiées à la science des données et à l'apprentissage automatique (traitement de données à grande échelle, analyse prédictive, calcul scientifique), qui vise à simplifier la gestion des paquets et de déploiement. Les versions de paquetages sont gérées par le système de gestion de paquets conda \cite{conda_website} et est adapté pour Windows, Linux et MacOS. Anaconda fournit interface graphique qui permet de lancer des applications, de gérer les librairies avec gestionnaire de paquets conda, et les environnements de développement. Plusieurs applications sont disponibles par défaut comme JupyterLab, Jupyter Notebook, QtConsole5, Spyder, Glue, Orange, RStudio, Visual Studio Code.  \\ \hline
  
  \begin{center}
    \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{images/chapitre7/jupyter.png}
  \end{minipage}
  \end{center}
  \centering \textbf{Jupyter Notebook} \cite{Kluyver2016jupyter} & Jupyter Notebook est un environnement de programmation interactif basé sur le web utilisé pour programmer en python, R, Ruby, Julia ou encore Scala qui permet de réalisé des notebooks contenant à la fois du texte en markdown et du code en Julia, Python, R etc.  \\ \hline

  \begin{center}
    \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{images/chapitre7/scikit_learn.png}
  \end{minipage}
  \end{center}
  \centering \textbf{Scikit-learn} \cite{pedregosa2011scikit} & Scikit-learn est une bibliothèque libre Python destinée à l'apprentissage automatique. Elle propose un ensemble d'outils efficace clé en main pour l’analyse et l’exploration de données. Cette bibliothèque prend en charge les algorithmes de classifications, de régression, du clustering, la réduction de dimensionnalité et de prétraitement des données pour l'extraction et la normalisation des caractéristiques.  \\ \hline

  \end{tabular}
	\caption{Indice de validité du clustering Hard}
	\label{tools}
\end{table}

\newpage

\begin{table}[H]
	\centering
	\addtolength{\leftskip} {-4cm}
	\addtolength{\rightskip}{-4.5cm}
	\begin{tabular}{|m{5cm}|m{14cm}|}
	\hline
	\rowcolor{blueforest}
	\color{white} \textbf{Outils | Packages} & \color{white} \textbf{Description}  \\
	\hline\hline
  %  >>>>>>>>>>>>>>
	\begin{center}
	    \begin{minipage}{.3\textwidth}
      \includegraphics[width=\textwidth]{images/chapitre7/pandas.png}
    \end{minipage}
	\end{center}
  \centering \textbf{Pandas} \cite{mckinney2010data} & Pandas est une bibliothèque écrite en Python qui permet la manipulation et l'analyse des données. Elle propose en particulier des structures de données et des opérations de manipulation de tableaux numériques et de séries temporelles. Elle propose principalement comme structures de données les Series, DataFrames, Panels, Panels4D. Et aussi des fonctionnalités comme la manipuler des données aisément et efficacement avec des index pouvant être des chaines de caractères, des outils pour lire et écrire des données structurées, gestion des données manquantes, le tri, le redimensionnement et , fusion et jointure de large volume de données et analyse de séries temporelles. \\ \hline
  % <<<<<<<<<<<<<<

  %  >>>>>>>>>>>>>>
  \begin{center}
	    \begin{minipage}{.3\textwidth}
      \includegraphics[width=\textwidth]{images/chapitre7/numpy.png}
    \end{minipage}
	\end{center}
	\centering \textbf{Numpy} \cite{2020NumPy-Array} & est une bibliothèque python pour le calcul scientifique qui fournit un objet tableau multidimensionnel, divers objets dérivés (tels que des tableaux et des matrices masqués) et un assortiment de routines pour des opérations rapides sur des tableaux, notamment mathématiques, logiques, manipulation de forme, tri, sélection, transformées de Fourier discrètes, algèbre linéaire de base, opérations statistiques de base, simulation aléatoire etc.  \\ \hline
  % <<<<<<<<<<<<<<
  \begin{center}
    \begin{minipage}{.3\textwidth}
    \includegraphics[width=\textwidth]{images/chapitre7/matplotlib.png}
  \end{minipage}
  \end{center}
  \centering \textbf{Matplotlib} \cite{hunter2007matplotlib} & Matplotlib est une bibliothèque du langage de programmation Python destinée à tracer et visualiser des données sous formes de graphiques en 2 ou 3 dimensions \cite{tosi2009matplotlib}. Cette bibliothèque permet de produire divers tracés par exemple des histogrammes, des fonctions de Rosenbrock, spirale logarithmique, graphiques d'erreurs, nuages de points etc.  \\ \hline

  \end{tabular}
	\caption{Indice de validité du clustering Hard}
	\label{tools}
\end{table}

\newpage

\begin{table}[H]
	\centering
	\addtolength{\leftskip} {-4cm}
	\addtolength{\rightskip}{-4.5cm}
	\begin{tabular}{|m{5cm}|m{14cm}|}
	\hline
	\rowcolor{blueforest}
	\color{white} \textbf{Outils | Packages} & \color{white} \textbf{Description}  \\
	\hline\hline
	\multicolumn{2}{|m{19cm}|}{\centering Les outils et packages supplémentaires utilisés sur Linux Ubuntu 20.04 LTS installé sur WSL2 : }\\ \hline
	\begin{center}
	    \begin{minipage}{.3\textwidth}
      \includegraphics[width=\textwidth]{images/chapitre7/stan.png}
    \end{minipage}
	\end{center}
	\centering \textbf{Stan} & Stan \cite{stan} est une plate-forme pour la modélisation statistique, l’analyse de données et la prédiction dans les sciences sociales, biologiques et physiques, l’ingénierie et les affaires. Il permet de spécifier les fonctions de densité de log afin d’obtenir une inférence statistique bayésienne complète avec échantillonnage MCMC (NUTS, HMC), une inférence bayésienne approximative avec inférence variationnelle (ADVI), une estimation du maximum de vraisemblance pénalisée avec optimisation (L-BFGS). La bibliothèque mathématique de Stan fournit des fonctions de probabilité différentiables et une algèbre linéaire (C++ autodiff). Stan peut être utilisé avec les langages d’analyse de données les plus populaires (R, Python, shell, MATLAB, Julia, Stata) et fonctionne sur toutes les principales plates-formes (Linux, Mac, Windows) \textbf{sauf la version 3 qui fonctionne sur Linux et Mac, c’est ce qui nous a poussée a utilisé Linux Ubuntu 20.04 LTS sur WSL2}. Dans l’implémentation nous avons utilisé Pystan 3.2.0 \cite{pystan} qui est une interface Python pour Stan, un package pour l'inférence bayésienne. \\ \hline
  \begin{center}
	    \begin{minipage}{.3\textwidth}
      \includegraphics[width=\textwidth]{images/chapitre7/arviz2.png}
    \end{minipage}
	\end{center}
	\centering \textbf{ArviZ} & ArviZ \cite{arviz_2019} est un package Python pour l'analyse exploratoire des modèles bayésiens. Comprend des fonctions d'analyse postérieure, de stockage de données, de diagnostic d'échantillons, de vérification de modèle et de comparaison. Ce package de fournir des outils backend indépendants pour les diagnostics et les visualisations de l'inférence bayésienne en Python, en convertissant d'abord les données d'inférence en objets xarray \cite{arviz}.  \\ \hline
  
  \end{tabular}
	\caption{Indice de validité du clustering Hard}
	\label{tools}
\end{table}

\subsection{Collecte et préparation des données}
\href{https://kdd.org/kdd-cup/view/kdd-cup-2010-student-performance-evaluation/Intro}{\color{blue}{KDD Cup 2010}} est une compétition d'exploration de données éducatives dans laquelle les participants sont chargés de prédire les performances des élèves aux problèmes algébriques en fonction des informations concernant les performances passées. \\
\textbf{Algèbre I 2005-2006} \cite{blog_kdd} est un jeu de données qui est fourni pour débuter et se familiarisé avec le format et le développement d’un modèle d’apprentissage. Une brève description du dataset initial avant l’étape du pre-processing est dans le tableau \ref{dataset_features_describe}.

\begin{table}[H]
	\centering
	\addtolength{\leftskip} {-4cm}
	\addtolength{\rightskip}{-4.5cm}
	\begin{tabular}{|m{5cm}|m{8cm}|m{4cm}|}
	\hline
	\rowcolor{blueforest}
	\color{white} \textbf{Caractéristique} & \color{white} \textbf{Description}  & \color{white} \textbf{Nombre Total}\\
	\hline
	\multicolumn{3}{|m{17cm}|}{\centering le nombre total de transactions = 809694. }\\ \hline
    \textbf{Anon Student Id} &  identifiant unique et anonyme d'un étudiant & 574 \\ \hline
    \textbf{Problem Name} &  identifiant unique d'un problème & 1084 \\ \hline 
    \textbf{Correct First Attempt} &  l'évaluation par le tuteur de la première tentative de l'étudiant 1 si correcte, 0 sinon. &  \\ \hline

    \multicolumn{3}{|m{17cm}|}{ \centering Et 11 autres carateristiques du dataset : \textbf{Row}, \textbf{Problem View}, \textbf{Step Start Time}, etc.} \\ \hline
  \end{tabular}
	\caption{Description et statistiques du jeu de données.}
	\label{dataset_features_describe}
\end{table}

\newpage
Les étapes suivies pour la collecte et la préparation du dataset sont illustré par la figure.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\textwidth]{images/chapitre7/preprocessing_steps.png}
	\end{center}
	\caption{Le pre-processing du dataset.}
	\label{datatset_pre-processing}
\end{figure}

\begin{description}
    \item[\textbf{Première étape : }] dans notre travail, nous nous concentrons sur la performance de l'apprenant qui est liée à l'item, au résultat obtenu par l'apprenant : (correct/incorrect soit 0 ou 1), ou en prenant un indice (hint).
    \item[\textbf{Deuxième étape : }] seulement les apprenants ayant au moins 10 interactions avec les items ont été sélectionner. Les valeurs qui ne sont pas binaire (0 ou 1) dans la colonne « correct » sont éliminées. Les valeurs de la colonne « user\char`_id »  et « item\char`_id » sont encoder et où « id = 0 » est remplacer le nombre total des apprenants et des items respectivement. L’encodage permet d’encoder les identifiants en valeur numérique, parce que le modèle IRT prend seulement des valeurs numériques à partir de 1. La colonne « answers\char`_using\char`_hint » ajouter au dataset sera utilisé pour calculer la matrice de similarité entre items selon notre critère : réponse correcte avec aide (hints) et sans aide, et incorrecte avec aide et sans aide.
\end{description}

\subsection{IRT}

\subsection{Clustering}

\section{Conclusion}

